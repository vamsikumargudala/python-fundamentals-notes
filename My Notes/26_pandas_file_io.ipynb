{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85a2a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6338c4af",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Reading CSV Files\n",
    "\n",
    "CSV (Comma-Separated Values) is the most common format for tabular data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972e8a01",
   "metadata": {},
   "source": [
    "### 1.1 Basic CSV Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7347a812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's create a sample CSV file to work with\n",
    "sample_data = pd.DataFrame({\n",
    "    'id': [1, 2, 3, 4, 5],\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve'],\n",
    "    'age': [25, 30, 35, 28, 22],\n",
    "    'salary': [50000, 60000, 75000, 55000, 45000],\n",
    "    'department': ['HR', 'IT', 'Finance', 'IT', 'HR']\n",
    "})\n",
    "sample_data.to_csv('employees.csv', index=False)\n",
    "print(\"Sample CSV created: employees.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9e85ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV file\n",
    "df = pd.read_csv('employees.csv')\n",
    "print(\"DataFrame from CSV:\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785c41e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View basic info about the DataFrame\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"\\nColumns:\", list(df.columns))\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef4ca3b",
   "metadata": {},
   "source": [
    "### 1.2 Common read_csv() Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559c0521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a more complex CSV for demonstration\n",
    "with open('complex_data.csv', 'w') as f:\n",
    "    f.write(\"# This is a comment line\\n\")\n",
    "    f.write(\"id;name;score;date\\n\")\n",
    "    f.write(\"1;Alice;95.5;2024-01-15\\n\")\n",
    "    f.write(\"2;Bob;87.3;2024-01-16\\n\")\n",
    "    f.write(\"3;Charlie;NA;2024-01-17\\n\")\n",
    "    f.write(\"4;Diana;92.1;2024-01-18\\n\")\n",
    "print(\"Complex CSV created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61840f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read with various parameters\n",
    "df = pd.read_csv(\n",
    "    'complex_data.csv',\n",
    "    sep=';',                    # Separator (delimiter)\n",
    "    comment='#',                # Skip lines starting with #\n",
    "    na_values=['NA', 'N/A'],    # Values to treat as NaN\n",
    "    parse_dates=['date']        # Parse date column\n",
    ")\n",
    "print(\"DataFrame with parameters:\")\n",
    "print(df)\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca1af6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read only specific columns\n",
    "df_subset = pd.read_csv('employees.csv', usecols=['name', 'salary'])\n",
    "print(\"Only specific columns:\")\n",
    "df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2337bf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read first n rows (useful for large files)\n",
    "df_head = pd.read_csv('employees.csv', nrows=3)\n",
    "print(\"First 3 rows only:\")\n",
    "df_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bee5750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a column as index\n",
    "df_indexed = pd.read_csv('employees.csv', index_col='id')\n",
    "print(\"With 'id' as index:\")\n",
    "df_indexed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6b320a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Writing CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8592dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'product': ['Apple', 'Banana', 'Orange'],\n",
    "    'price': [1.50, 0.75, 1.25],\n",
    "    'quantity': [100, 150, 80]\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4171ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic write (includes index by default)\n",
    "df.to_csv('products_with_index.csv')\n",
    "print(\"With index:\")\n",
    "print(open('products_with_index.csv').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67149784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write without index (most common)\n",
    "df.to_csv('products.csv', index=False)\n",
    "print(\"Without index:\")\n",
    "print(open('products.csv').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc2afdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write with custom separator\n",
    "df.to_csv('products_semicolon.csv', index=False, sep=';')\n",
    "print(\"With semicolon separator:\")\n",
    "print(open('products_semicolon.csv').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bee5d4f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Reading Excel Files\n",
    "\n",
    "Pandas can read Excel files (.xlsx, .xls) using `openpyxl` or `xlrd` libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22679646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample Excel file\n",
    "df_excel = pd.DataFrame({\n",
    "    'name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'math': [90, 85, 88],\n",
    "    'english': [88, 92, 85]\n",
    "})\n",
    "\n",
    "# Note: Requires openpyxl package\n",
    "try:\n",
    "    df_excel.to_excel('students.xlsx', sheet_name='Grades', index=False)\n",
    "    print(\"Excel file created: students.xlsx\")\n",
    "except ModuleNotFoundError:\n",
    "    print(\"Install openpyxl: pip install openpyxl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0e62a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Excel file\n",
    "try:\n",
    "    df = pd.read_excel('students.xlsx', sheet_name='Grades')\n",
    "    print(\"DataFrame from Excel:\")\n",
    "    print(df)\n",
    "except FileNotFoundError:\n",
    "    print(\"Excel file not found\")\n",
    "except ModuleNotFoundError:\n",
    "    print(\"Install openpyxl: pip install openpyxl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985f3ff9",
   "metadata": {},
   "source": [
    "### 3.1 Reading Multiple Sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761d035e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Excel file with multiple sheets\n",
    "try:\n",
    "    with pd.ExcelWriter('multi_sheet.xlsx') as writer:\n",
    "        df_excel.to_excel(writer, sheet_name='Sheet1', index=False)\n",
    "        df_excel.to_excel(writer, sheet_name='Sheet2', index=False)\n",
    "    print(\"Multi-sheet Excel created\")\n",
    "except ModuleNotFoundError:\n",
    "    print(\"Install openpyxl: pip install openpyxl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605838a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all sheets into a dictionary\n",
    "try:\n",
    "    all_sheets = pd.read_excel('multi_sheet.xlsx', sheet_name=None)\n",
    "    print(\"Sheet names:\", list(all_sheets.keys()))\n",
    "    print(\"\\nSheet1:\")\n",
    "    print(all_sheets['Sheet1'])\n",
    "except FileNotFoundError:\n",
    "    print(\"Excel file not found\")\n",
    "except ModuleNotFoundError:\n",
    "    print(\"Install openpyxl: pip install openpyxl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f18afb0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Reading JSON Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c30b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create JSON file\n",
    "import json\n",
    "\n",
    "data = [\n",
    "    {\"name\": \"Alice\", \"age\": 25, \"city\": \"NYC\"},\n",
    "    {\"name\": \"Bob\", \"age\": 30, \"city\": \"LA\"},\n",
    "    {\"name\": \"Charlie\", \"age\": 35, \"city\": \"Chicago\"}\n",
    "]\n",
    "\n",
    "with open('people.json', 'w') as f:\n",
    "    json.dump(data, f)\n",
    "print(\"JSON file created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e124383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read JSON file\n",
    "df_json = pd.read_json('people.json')\n",
    "print(\"DataFrame from JSON:\")\n",
    "df_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b585f96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write DataFrame to JSON\n",
    "df_json.to_json('people_output.json', orient='records', indent=2)\n",
    "print(\"JSON output:\")\n",
    "print(open('people_output.json').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163fb7ba",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Reading from URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d09c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas can read directly from URLs\n",
    "# Example (commented out to avoid network calls):\n",
    "\n",
    "# url = 'https://example.com/data.csv'\n",
    "# df = pd.read_csv(url)\n",
    "\n",
    "# This works for CSV, JSON, Excel, etc.\n",
    "print(\"You can read directly from URLs:\")\n",
    "print(\"df = pd.read_csv('https://example.com/data.csv')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ad1895",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Handling Large Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729e795d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a larger sample file\n",
    "np.random.seed(42)\n",
    "large_df = pd.DataFrame({\n",
    "    'id': range(10000),\n",
    "    'value': np.random.randn(10000),\n",
    "    'category': np.random.choice(['A', 'B', 'C'], 10000)\n",
    "})\n",
    "large_df.to_csv('large_file.csv', index=False)\n",
    "print(f\"Created large_file.csv with {len(large_df)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989241b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in chunks for memory efficiency\n",
    "chunk_size = 2000\n",
    "chunks = []\n",
    "\n",
    "for chunk in pd.read_csv('large_file.csv', chunksize=chunk_size):\n",
    "    # Process each chunk (e.g., filter, aggregate)\n",
    "    filtered = chunk[chunk['value'] > 0]  # Example filter\n",
    "    chunks.append(filtered)\n",
    "\n",
    "# Combine processed chunks\n",
    "result = pd.concat(chunks, ignore_index=True)\n",
    "print(f\"Processed {len(result)} rows with positive values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5bb576",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Quick Reference: Common Parameters\n",
    "\n",
    "### read_csv() Parameters:\n",
    "\n",
    "| Parameter | Description | Example |\n",
    "|-----------|-------------|--------|\n",
    "| `sep` | Delimiter | `sep=';'` |\n",
    "| `header` | Row number for headers | `header=0` |\n",
    "| `names` | Custom column names | `names=['a','b']` |\n",
    "| `index_col` | Column to use as index | `index_col='id'` |\n",
    "| `usecols` | Columns to read | `usecols=['a','b']` |\n",
    "| `nrows` | Number of rows to read | `nrows=100` |\n",
    "| `skiprows` | Rows to skip | `skiprows=5` |\n",
    "| `na_values` | Values to treat as NaN | `na_values=['NA']` |\n",
    "| `parse_dates` | Parse date columns | `parse_dates=['date']` |\n",
    "| `dtype` | Column data types | `dtype={'id': int}` |\n",
    "| `encoding` | File encoding | `encoding='utf-8'` |\n",
    "\n",
    "### to_csv() Parameters:\n",
    "\n",
    "| Parameter | Description | Example |\n",
    "|-----------|-------------|--------|\n",
    "| `index` | Write index | `index=False` |\n",
    "| `sep` | Delimiter | `sep=';'` |\n",
    "| `columns` | Columns to write | `columns=['a','b']` |\n",
    "| `header` | Write header | `header=False` |\n",
    "| `mode` | Write mode | `mode='a'` (append) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ea0521",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù Practice Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64db525",
   "metadata": {},
   "source": [
    "### Problem 1: Create and Read CSV\n",
    "1. Create a DataFrame with student data: id, name, math_score, science_score\n",
    "2. Save it to 'student_scores.csv' without the index\n",
    "3. Read it back and display first 3 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d3089f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a74c24",
   "metadata": {},
   "source": [
    "### Problem 2: Read with Custom Parameters\n",
    "Create a CSV file 'custom_data.csv' with:\n",
    "- Semicolon separator\n",
    "- A comment line at the top\n",
    "- Some 'NA' values\n",
    "\n",
    "Then read it with appropriate parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0523fe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c01033",
   "metadata": {},
   "source": [
    "### Problem 3: Selective Reading\n",
    "Using 'employees.csv':\n",
    "1. Read only the 'name' and 'department' columns\n",
    "2. Read only the first 2 rows\n",
    "3. Read with 'id' as the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18f63f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abeb3727",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ad932f",
   "metadata": {},
   "source": [
    "### Solution 1: Create and Read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2404edbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1\n",
    "# Create DataFrame\n",
    "students = pd.DataFrame({\n",
    "    'id': [1, 2, 3, 4, 5],\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve'],\n",
    "    'math_score': [90, 85, 78, 92, 88],\n",
    "    'science_score': [88, 90, 82, 95, 85]\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "students.to_csv('student_scores.csv', index=False)\n",
    "print(\"Saved student_scores.csv\")\n",
    "\n",
    "# Read back\n",
    "df = pd.read_csv('student_scores.csv')\n",
    "print(\"\\nFirst 3 rows:\")\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5c8146",
   "metadata": {},
   "source": [
    "### Solution 2: Read with Custom Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765ac2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 2\n",
    "# Create custom CSV\n",
    "with open('custom_data.csv', 'w') as f:\n",
    "    f.write(\"# Custom data file\\n\")\n",
    "    f.write(\"product;price;stock\\n\")\n",
    "    f.write(\"Apple;1.50;100\\n\")\n",
    "    f.write(\"Banana;NA;150\\n\")\n",
    "    f.write(\"Orange;1.25;NA\\n\")\n",
    "\n",
    "print(\"File content:\")\n",
    "print(open('custom_data.csv').read())\n",
    "\n",
    "# Read with parameters\n",
    "df = pd.read_csv(\n",
    "    'custom_data.csv',\n",
    "    sep=';',\n",
    "    comment='#',\n",
    "    na_values=['NA']\n",
    ")\n",
    "print(\"DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e817dd",
   "metadata": {},
   "source": [
    "### Solution 3: Selective Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d828ba27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 3\n",
    "\n",
    "# 1. Read only name and department\n",
    "df1 = pd.read_csv('employees.csv', usecols=['name', 'department'])\n",
    "print(\"1. Only name and department:\")\n",
    "print(df1)\n",
    "\n",
    "# 2. Read first 2 rows\n",
    "df2 = pd.read_csv('employees.csv', nrows=2)\n",
    "print(\"\\n2. First 2 rows:\")\n",
    "print(df2)\n",
    "\n",
    "# 3. Read with id as index\n",
    "df3 = pd.read_csv('employees.csv', index_col='id')\n",
    "print(\"\\n3. With id as index:\")\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ee138e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üßπ Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4915adda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up created files\n",
    "import os\n",
    "\n",
    "files_to_remove = [\n",
    "    'employees.csv', 'products.csv', 'products_with_index.csv',\n",
    "    'products_semicolon.csv', 'complex_data.csv', 'students.xlsx',\n",
    "    'multi_sheet.xlsx', 'people.json', 'people_output.json',\n",
    "    'large_file.csv', 'student_scores.csv', 'custom_data.csv'\n",
    "]\n",
    "\n",
    "for file in files_to_remove:\n",
    "    if os.path.exists(file):\n",
    "        os.remove(file)\n",
    "        print(f\"Removed: {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dd8434",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìå Summary\n",
    "\n",
    "| Operation | Function | Key Parameters |\n",
    "|-----------|----------|----------------|\n",
    "| **Read CSV** | `pd.read_csv()` | `sep`, `usecols`, `nrows`, `index_col` |\n",
    "| **Write CSV** | `df.to_csv()` | `index=False`, `sep` |\n",
    "| **Read Excel** | `pd.read_excel()` | `sheet_name` |\n",
    "| **Write Excel** | `df.to_excel()` | `sheet_name`, `index` |\n",
    "| **Read JSON** | `pd.read_json()` | `orient` |\n",
    "| **Write JSON** | `df.to_json()` | `orient`, `indent` |\n",
    "\n",
    "**Next:** [27_pandas_exploration.ipynb](27_pandas_exploration.ipynb) - Data exploration and basic analysis"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
